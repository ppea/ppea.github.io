<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Welcome to int32 top. This site serves as a personal knowledge base for me to record my thoughts and ideas.  It is also a place for me to share my knowledge and experience with the world.  I hope you find something useful here."><meta name=author content=int32top><link href=https://localhost:8000/zh/09.AI/NOTE-D2L/CH7-MODERN-CNN/ch7-modern-cnn/ rel=canonical><link href=../../CH6-CNN/ch6-cnn/ rel=prev><link href=../../../RL/rl/ rel=next><link rel=icon href=../../../../../static/images/logo.png><meta name=generator content="mkdocs-1.6.0, mkdocs-material-9.5.25"><title>现代卷积神经网络 - 整数之上</title><link rel=stylesheet href=../../../../../assets/stylesheets/main.6543a935.min.css><link rel=stylesheet href=../../../../../assets/stylesheets/palette.06af60db.min.css><style>.md-tag.md-tag--default-tag{--md-tag-icon:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 80v149.5c0 17 6.7 33.3 18.7 45.3l176 176c25 25 65.5 25 90.5 0l133.5-133.5c25-25 25-65.5 0-90.5l-176-176c-12-12-28.3-18.7-45.3-18.7H48C21.5 32 0 53.5 0 80zm112 32a32 32 0 1 1 0 64 32 32 0 1 1 0-64z"/></svg>');}.md-tag.md-tag--hardware-tag{--md-tag-icon:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M176 24c0-13.3-10.7-24-24-24s-24 10.7-24 24v40c-35.3 0-64 28.7-64 64H24c-13.3 0-24 10.7-24 24s10.7 24 24 24h40v56H24c-13.3 0-24 10.7-24 24s10.7 24 24 24h40v56H24c-13.3 0-24 10.7-24 24s10.7 24 24 24h40c0 35.3 28.7 64 64 64v40c0 13.3 10.7 24 24 24s24-10.7 24-24v-40h56v40c0 13.3 10.7 24 24 24s24-10.7 24-24v-40h56v40c0 13.3 10.7 24 24 24s24-10.7 24-24v-40c35.3 0 64-28.7 64-64h40c13.3 0 24-10.7 24-24s-10.7-24-24-24h-40v-56h40c13.3 0 24-10.7 24-24s-10.7-24-24-24h-40v-56h40c13.3 0 24-10.7 24-24s-10.7-24-24-24h-40c0-35.3-28.7-64-64-64V24c0-13.3-10.7-24-24-24s-24 10.7-24 24v40h-56V24c0-13.3-10.7-24-24-24s-24 10.7-24 24v40h-56V24zm-16 104h192c17.7 0 32 14.3 32 32v192c0 17.7-14.3 32-32 32H160c-17.7 0-32-14.3-32-32V160c0-17.7 14.3-32 32-32zm192 32H160v192h192V160z"/></svg>');}.md-tag.md-tag--software-tag{--md-tag-icon:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 96c0-35.3 28.7-64 64-64h384c35.3 0 64 28.7 64 64v256h-64V96H128v256H64V96zM0 403.2C0 392.6 8.6 384 19.2 384h601.6c10.6 0 19.2 8.6 19.2 19.2 0 42.4-34.4 76.8-76.8 76.8H76.8C34.4 480 0 445.6 0 403.2zM281 209l-31 31 31 31c9.4 9.4 9.4 24.6 0 33.9s-24.6 9.4-33.9 0l-48-48c-9.4-9.4-9.4-24.6 0-33.9l48-48c9.4-9.4 24.6-9.4 33.9 0s9.4 24.6 0 33.9zm112-34 48 48c9.4 9.4 9.4 24.6 0 33.9l-48 48c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l31-31-31-31c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0z"/></svg>');}</style><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto Slab";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config",""),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link rel=stylesheet href=../../../../../assets/stylesheets/custom.00c04c01.min.css></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=light-blue data-md-color-accent=deep-purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#_1 class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label=不再显示此消息> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> For updates follow <strong>@Feng Yan</strong> on <a rel=me href=https://github.com/ppea> <span class="twemoji mastodon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </span> <strong>Github</strong> </a> </div> <script>var content,el=document.querySelector("[data-md-component=announce]");el&&(content=el.querySelector(".md-typeset"),__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0))</script> </aside> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../../../../ title=整数之上 class="md-header__button md-logo" aria-label=整数之上 data-md-component=logo> <img src=../../../../../static/images/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> 整数之上 </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 现代卷积神经网络 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=light-blue data-md-color-accent=deep-purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=cyan data-md-color-accent=deep-purple aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <div class=md-header__option> <div class=md-select> <button class="md-header__button md-icon" aria-label=选择当前语言> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.52 17.52 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04M18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12m-2.62 7 1.62-4.33L19.12 17h-3.24Z"/></svg> </button> <div class=md-select__inner> <ul class=md-select__list> <li class=md-select__item> <a href=../../../../../09.AI/NOTE-D2L/CH7-MODERN-CNN/ch7-modern-cnn/ hreflang=en class=md-select__link> English </a> </li> <li class=md-select__item> <a href=./ hreflang=zh class=md-select__link> 简体中文 </a> </li> </ul> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 320 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg> </label> <nav class=md-search__options aria-label=查找> <a href=javascript:void(0) class="md-search__icon md-icon" title=分享 aria-label=分享 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=清空当前内容 aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/ppea/ppea.github.io title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> ppea.github.io </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../../../ title=整数之上 class="md-nav__button md-logo" aria-label=整数之上 data-md-component=logo> <img src=../../../../../static/images/logo.png alt=logo> </a> 整数之上 </label> <div class=md-nav__source> <a href=https://github.com/ppea/ppea.github.io title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> ppea.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../ class=md-nav__link> <span class=md-ellipsis> Index </span> </a> </li> <li class=md-nav__item> <a href=../../../../about/ class=md-nav__link> <span class=md-ellipsis> About </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../01.MATH/math/ class=md-nav__link> <span class=md-ellipsis> 01.数学 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../02.CS/CS/ class=md-nav__link> <span class=md-ellipsis> 02.计算机科学 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../03.CODING/coding/ class=md-nav__link> <span class=md-ellipsis> 03.编程 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../04.EMBEDDED/embedded-sys/ class=md-nav__link> <span class=md-ellipsis> 04.嵌入式系统 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../05.DSP/dsp/ class=md-nav__link> <span class=md-ellipsis> 05.数字信号处理 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../06.IOT/iot/ class=md-nav__link> <span class=md-ellipsis> 06.物联网 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../07.MN/mn/ class=md-nav__link> <span class=md-ellipsis> 07.移动通信 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../08.CLOUD/cloud/ class=md-nav__link> <span class=md-ellipsis> 08.云 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_11 checked> <label class=md-nav__link for=__nav_11 id=__nav_11_label tabindex=0> <span class=md-ellipsis> 09.人工智能 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_11_label aria-expanded=true> <label class=md-nav__title for=__nav_11> <span class="md-nav__icon md-icon"></span> 09.人工智能 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../ai/ class=md-nav__link> <span class=md-ellipsis> 人工智能 </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../BASICS/basics/ class=md-nav__link> <span class=md-ellipsis> 基础 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../CNN/cnn/ class=md-nav__link> <span class=md-ellipsis> 卷积神经网络 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../CV/cv/ class=md-nav__link> <span class=md-ellipsis> 计算机视觉 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../FL/fl/ class=md-nav__link> <span class=md-ellipsis> 联邦学习 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../FRAMEWORKS/frameworks/ class=md-nav__link> <span class=md-ellipsis> 框架 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../GAN/gan/ class=md-nav__link> <span class=md-ellipsis> 生成对抗网络 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../GAUSSIAN-PROCESS/gaussian-process/ class=md-nav__link> <span class=md-ellipsis> GAUSSIAN PROCESS </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../GNN/gnn/ class=md-nav__link> <span class=md-ellipsis> 图神经网络 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../KERAS/keras/ class=md-nav__link> <span class=md-ellipsis> KERAS </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../LNN/lnn/ class=md-nav__link> <span class=md-ellipsis> 线性神经网络 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../MLP/mlp/ class=md-nav__link> <span class=md-ellipsis> 多层感知机 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../MULTI-AGENT/multi-agent/ class=md-nav__link> <span class=md-ellipsis> MULTI AGENT </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../NLP/nlp/ class=md-nav__link> <span class=md-ellipsis> 自然语言处理 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_11_15 checked> <label class=md-nav__link for=__nav_11_15 id=__nav_11_15_label tabindex=0> <span class=md-ellipsis> NOTE D2L </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_11_15_label aria-expanded=true> <label class=md-nav__title for=__nav_11_15> <span class="md-nav__icon md-icon"></span> NOTE D2L </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../CH1-INTRO/ch1-intro/ class=md-nav__link> <span class=md-ellipsis> CH1 INTRO </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../CH2-PRE/ch2-pre/ class=md-nav__link> <span class=md-ellipsis> CH2 PRE </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../CH3-LNN/ch3-lnn/ class=md-nav__link> <span class=md-ellipsis> CH3 LNN </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../CH4-MLP/ch4-mlp/ class=md-nav__link> <span class=md-ellipsis> CH4 MLP </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../CH5-DL-COMPUTING/ch5-dl-computing/ class=md-nav__link> <span class=md-ellipsis> CH5 DL COMPUTING </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../CH6-CNN/ch6-cnn/ class=md-nav__link> <span class=md-ellipsis> CH6 CNN </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_11_15_7 checked> <label class=md-nav__link for=__nav_11_15_7 id=__nav_11_15_7_label tabindex=0> <span class=md-ellipsis> CH7 MODERN CNN </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_11_15_7_label aria-expanded=true> <label class=md-nav__title for=__nav_11_15_7> <span class="md-nav__icon md-icon"></span> CH7 MODERN CNN </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 现代卷积神经网络 </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 现代卷积神经网络 </span> </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#71-alexnet class=md-nav__link> <span class=md-ellipsis> 7.1. 深度卷积神经网络（AlexNet） </span> </a> <nav class=md-nav aria-label="7.1. 深度卷积神经网络（AlexNet）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#711 class=md-nav__link> <span class=md-ellipsis> 7.1.1. 学习表征 </span> </a> <nav class=md-nav aria-label="7.1.1. 学习表征"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#7111 class=md-nav__link> <span class=md-ellipsis> 7.1.1.1 缺少的成分：数据 </span> </a> </li> <li class=md-nav__item> <a href=#7112 class=md-nav__link> <span class=md-ellipsis> 7.1.1.2 缺少的成分：硬件 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#712-alexnet class=md-nav__link> <span class=md-ellipsis> 7.1.2. AlexNet </span> </a> <nav class=md-nav aria-label="7.1.2. AlexNet"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#7121 class=md-nav__link> <span class=md-ellipsis> 7.1.2.1 模型设计 </span> </a> </li> <li class=md-nav__item> <a href=#7122 class=md-nav__link> <span class=md-ellipsis> 7.1.2.2 激活函数 </span> </a> </li> <li class=md-nav__item> <a href=#7123 class=md-nav__link> <span class=md-ellipsis> 7.1.2.3 容量控制和预处理 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#713 class=md-nav__link> <span class=md-ellipsis> 7.1.3. 读取数据集 </span> </a> </li> <li class=md-nav__item> <a href=#714-alexnet class=md-nav__link> <span class=md-ellipsis> 7.1.4. 训练AlexNet </span> </a> </li> <li class=md-nav__item> <a href=#715 class=md-nav__link> <span class=md-ellipsis> 7.1.5. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#72-vgg class=md-nav__link> <span class=md-ellipsis> 7.2. 使用块的网络（VGG） </span> </a> <nav class=md-nav aria-label="7.2. 使用块的网络（VGG）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#721-vgg class=md-nav__link> <span class=md-ellipsis> 7.2.1. VGG块 </span> </a> </li> <li class=md-nav__item> <a href=#722-vgg class=md-nav__link> <span class=md-ellipsis> 7.2.2. VGG网络 </span> </a> </li> <li class=md-nav__item> <a href=#723 class=md-nav__link> <span class=md-ellipsis> 7.2.3. 训练模型 </span> </a> </li> <li class=md-nav__item> <a href=#724 class=md-nav__link> <span class=md-ellipsis> 7.2.4. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#73-nin class=md-nav__link> <span class=md-ellipsis> 7.3. 网络中的网络（NiN） </span> </a> <nav class=md-nav aria-label="7.3. 网络中的网络（NiN）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#731-nin class=md-nav__link> <span class=md-ellipsis> 7.3.1. NiN块 </span> </a> </li> <li class=md-nav__item> <a href=#732-nin class=md-nav__link> <span class=md-ellipsis> 7.3.2. NiN模型 </span> </a> </li> <li class=md-nav__item> <a href=#733 class=md-nav__link> <span class=md-ellipsis> 7.3.3. 训练模型 </span> </a> </li> <li class=md-nav__item> <a href=#734 class=md-nav__link> <span class=md-ellipsis> 7.3.4. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#74-googlenet class=md-nav__link> <span class=md-ellipsis> 7.4. 含并行连结的网络（GoogLeNet） </span> </a> <nav class=md-nav aria-label="7.4. 含并行连结的网络（GoogLeNet）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#741-inception class=md-nav__link> <span class=md-ellipsis> 7.4.1. Inception块 </span> </a> </li> <li class=md-nav__item> <a href=#742-googlenet class=md-nav__link> <span class=md-ellipsis> 7.4.2. GoogLeNet模型 </span> </a> </li> <li class=md-nav__item> <a href=#743 class=md-nav__link> <span class=md-ellipsis> 7.4.3. 训练模型 </span> </a> </li> <li class=md-nav__item> <a href=#744 class=md-nav__link> <span class=md-ellipsis> 7.4.4. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#75 class=md-nav__link> <span class=md-ellipsis> 7.5. 批量规范化 </span> </a> <nav class=md-nav aria-label="7.5. 批量规范化"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#751 class=md-nav__link> <span class=md-ellipsis> 7.5.1. 训练深层网络 </span> </a> </li> <li class=md-nav__item> <a href=#752 class=md-nav__link> <span class=md-ellipsis> 7.5.2. 批量规范化层 </span> </a> <nav class=md-nav aria-label="7.5.2. 批量规范化层"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#7521 class=md-nav__link> <span class=md-ellipsis> 7.5.2.1 全连接层 </span> </a> </li> <li class=md-nav__item> <a href=#7522 class=md-nav__link> <span class=md-ellipsis> 7.5.2.2 卷积层 </span> </a> </li> <li class=md-nav__item> <a href=#7523 class=md-nav__link> <span class=md-ellipsis> 7.5.2.3 预测过程中的批量规范化 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#753 class=md-nav__link> <span class=md-ellipsis> 7.5.3. 从零实现 </span> </a> </li> <li class=md-nav__item> <a href=#754-lenet class=md-nav__link> <span class=md-ellipsis> 7.5.4. 使用批量规范化层的 LeNet </span> </a> </li> <li class=md-nav__item> <a href=#755 class=md-nav__link> <span class=md-ellipsis> 7.5.5. 简明实现 </span> </a> </li> <li class=md-nav__item> <a href=#756 class=md-nav__link> <span class=md-ellipsis> 7.5.6. 争议 </span> </a> </li> <li class=md-nav__item> <a href=#757 class=md-nav__link> <span class=md-ellipsis> 7.5.7. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#76-resnet class=md-nav__link> <span class=md-ellipsis> 7.6. 残差网络（ResNet） </span> </a> <nav class=md-nav aria-label="7.6. 残差网络（ResNet）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#761 class=md-nav__link> <span class=md-ellipsis> 7.6.1. 函数类 </span> </a> </li> <li class=md-nav__item> <a href=#762 class=md-nav__link> <span class=md-ellipsis> 7.6.2. 残差块 </span> </a> </li> <li class=md-nav__item> <a href=#763-resnet class=md-nav__link> <span class=md-ellipsis> 7.6.3. ResNet模型 </span> </a> </li> <li class=md-nav__item> <a href=#764 class=md-nav__link> <span class=md-ellipsis> 7.6.4. 训练模型 </span> </a> </li> <li class=md-nav__item> <a href=#765 class=md-nav__link> <span class=md-ellipsis> 7.6.5. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#77-densenet class=md-nav__link> <span class=md-ellipsis> 7.7. 稠密连接网络（DenseNet） </span> </a> <nav class=md-nav aria-label="7.7. 稠密连接网络（DenseNet）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#771-resnetdensenet class=md-nav__link> <span class=md-ellipsis> 7.7.1. 从ResNet到DenseNet </span> </a> </li> <li class=md-nav__item> <a href=#772 class=md-nav__link> <span class=md-ellipsis> 7.7.2. 稠密块体 </span> </a> </li> <li class=md-nav__item> <a href=#773 class=md-nav__link> <span class=md-ellipsis> 7.7.3. 过渡层 </span> </a> </li> <li class=md-nav__item> <a href=#774-densenet class=md-nav__link> <span class=md-ellipsis> 7.7.4. DenseNet模型 </span> </a> </li> <li class=md-nav__item> <a href=#775 class=md-nav__link> <span class=md-ellipsis> 7.7.5. 训练模型 </span> </a> </li> <li class=md-nav__item> <a href=#776 class=md-nav__link> <span class=md-ellipsis> 7.7.6. 小结 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../RL/rl/ class=md-nav__link> <span class=md-ellipsis> 强化学习 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../RNN/rnn/ class=md-nav__link> <span class=md-ellipsis> 循环神经网络 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../TL/tl/ class=md-nav__link> <span class=md-ellipsis> 迁移学习 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../TRANSFORMER/transformer/ class=md-nav__link> <span class=md-ellipsis> “变形金刚” </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../10.ROBOT/robot/ class=md-nav__link> <span class=md-ellipsis> 10.机器人 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../97.FAVORITES/favorites/ class=md-nav__link> <span class=md-ellipsis> 97.收藏夹 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../98.DEV/dev/ class=md-nav__link> <span class=md-ellipsis> 98.开发 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../../99.PROJECT/project/ class=md-nav__link> <span class=md-ellipsis> 99.项目 </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#71-alexnet class=md-nav__link> <span class=md-ellipsis> 7.1. 深度卷积神经网络（AlexNet） </span> </a> <nav class=md-nav aria-label="7.1. 深度卷积神经网络（AlexNet）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#711 class=md-nav__link> <span class=md-ellipsis> 7.1.1. 学习表征 </span> </a> <nav class=md-nav aria-label="7.1.1. 学习表征"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#7111 class=md-nav__link> <span class=md-ellipsis> 7.1.1.1 缺少的成分：数据 </span> </a> </li> <li class=md-nav__item> <a href=#7112 class=md-nav__link> <span class=md-ellipsis> 7.1.1.2 缺少的成分：硬件 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#712-alexnet class=md-nav__link> <span class=md-ellipsis> 7.1.2. AlexNet </span> </a> <nav class=md-nav aria-label="7.1.2. AlexNet"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#7121 class=md-nav__link> <span class=md-ellipsis> 7.1.2.1 模型设计 </span> </a> </li> <li class=md-nav__item> <a href=#7122 class=md-nav__link> <span class=md-ellipsis> 7.1.2.2 激活函数 </span> </a> </li> <li class=md-nav__item> <a href=#7123 class=md-nav__link> <span class=md-ellipsis> 7.1.2.3 容量控制和预处理 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#713 class=md-nav__link> <span class=md-ellipsis> 7.1.3. 读取数据集 </span> </a> </li> <li class=md-nav__item> <a href=#714-alexnet class=md-nav__link> <span class=md-ellipsis> 7.1.4. 训练AlexNet </span> </a> </li> <li class=md-nav__item> <a href=#715 class=md-nav__link> <span class=md-ellipsis> 7.1.5. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#72-vgg class=md-nav__link> <span class=md-ellipsis> 7.2. 使用块的网络（VGG） </span> </a> <nav class=md-nav aria-label="7.2. 使用块的网络（VGG）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#721-vgg class=md-nav__link> <span class=md-ellipsis> 7.2.1. VGG块 </span> </a> </li> <li class=md-nav__item> <a href=#722-vgg class=md-nav__link> <span class=md-ellipsis> 7.2.2. VGG网络 </span> </a> </li> <li class=md-nav__item> <a href=#723 class=md-nav__link> <span class=md-ellipsis> 7.2.3. 训练模型 </span> </a> </li> <li class=md-nav__item> <a href=#724 class=md-nav__link> <span class=md-ellipsis> 7.2.4. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#73-nin class=md-nav__link> <span class=md-ellipsis> 7.3. 网络中的网络（NiN） </span> </a> <nav class=md-nav aria-label="7.3. 网络中的网络（NiN）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#731-nin class=md-nav__link> <span class=md-ellipsis> 7.3.1. NiN块 </span> </a> </li> <li class=md-nav__item> <a href=#732-nin class=md-nav__link> <span class=md-ellipsis> 7.3.2. NiN模型 </span> </a> </li> <li class=md-nav__item> <a href=#733 class=md-nav__link> <span class=md-ellipsis> 7.3.3. 训练模型 </span> </a> </li> <li class=md-nav__item> <a href=#734 class=md-nav__link> <span class=md-ellipsis> 7.3.4. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#74-googlenet class=md-nav__link> <span class=md-ellipsis> 7.4. 含并行连结的网络（GoogLeNet） </span> </a> <nav class=md-nav aria-label="7.4. 含并行连结的网络（GoogLeNet）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#741-inception class=md-nav__link> <span class=md-ellipsis> 7.4.1. Inception块 </span> </a> </li> <li class=md-nav__item> <a href=#742-googlenet class=md-nav__link> <span class=md-ellipsis> 7.4.2. GoogLeNet模型 </span> </a> </li> <li class=md-nav__item> <a href=#743 class=md-nav__link> <span class=md-ellipsis> 7.4.3. 训练模型 </span> </a> </li> <li class=md-nav__item> <a href=#744 class=md-nav__link> <span class=md-ellipsis> 7.4.4. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#75 class=md-nav__link> <span class=md-ellipsis> 7.5. 批量规范化 </span> </a> <nav class=md-nav aria-label="7.5. 批量规范化"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#751 class=md-nav__link> <span class=md-ellipsis> 7.5.1. 训练深层网络 </span> </a> </li> <li class=md-nav__item> <a href=#752 class=md-nav__link> <span class=md-ellipsis> 7.5.2. 批量规范化层 </span> </a> <nav class=md-nav aria-label="7.5.2. 批量规范化层"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#7521 class=md-nav__link> <span class=md-ellipsis> 7.5.2.1 全连接层 </span> </a> </li> <li class=md-nav__item> <a href=#7522 class=md-nav__link> <span class=md-ellipsis> 7.5.2.2 卷积层 </span> </a> </li> <li class=md-nav__item> <a href=#7523 class=md-nav__link> <span class=md-ellipsis> 7.5.2.3 预测过程中的批量规范化 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#753 class=md-nav__link> <span class=md-ellipsis> 7.5.3. 从零实现 </span> </a> </li> <li class=md-nav__item> <a href=#754-lenet class=md-nav__link> <span class=md-ellipsis> 7.5.4. 使用批量规范化层的 LeNet </span> </a> </li> <li class=md-nav__item> <a href=#755 class=md-nav__link> <span class=md-ellipsis> 7.5.5. 简明实现 </span> </a> </li> <li class=md-nav__item> <a href=#756 class=md-nav__link> <span class=md-ellipsis> 7.5.6. 争议 </span> </a> </li> <li class=md-nav__item> <a href=#757 class=md-nav__link> <span class=md-ellipsis> 7.5.7. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#76-resnet class=md-nav__link> <span class=md-ellipsis> 7.6. 残差网络（ResNet） </span> </a> <nav class=md-nav aria-label="7.6. 残差网络（ResNet）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#761 class=md-nav__link> <span class=md-ellipsis> 7.6.1. 函数类 </span> </a> </li> <li class=md-nav__item> <a href=#762 class=md-nav__link> <span class=md-ellipsis> 7.6.2. 残差块 </span> </a> </li> <li class=md-nav__item> <a href=#763-resnet class=md-nav__link> <span class=md-ellipsis> 7.6.3. ResNet模型 </span> </a> </li> <li class=md-nav__item> <a href=#764 class=md-nav__link> <span class=md-ellipsis> 7.6.4. 训练模型 </span> </a> </li> <li class=md-nav__item> <a href=#765 class=md-nav__link> <span class=md-ellipsis> 7.6.5. 小结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#77-densenet class=md-nav__link> <span class=md-ellipsis> 7.7. 稠密连接网络（DenseNet） </span> </a> <nav class=md-nav aria-label="7.7. 稠密连接网络（DenseNet）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#771-resnetdensenet class=md-nav__link> <span class=md-ellipsis> 7.7.1. 从ResNet到DenseNet </span> </a> </li> <li class=md-nav__item> <a href=#772 class=md-nav__link> <span class=md-ellipsis> 7.7.2. 稠密块体 </span> </a> </li> <li class=md-nav__item> <a href=#773 class=md-nav__link> <span class=md-ellipsis> 7.7.3. 过渡层 </span> </a> </li> <li class=md-nav__item> <a href=#774-densenet class=md-nav__link> <span class=md-ellipsis> 7.7.4. DenseNet模型 </span> </a> </li> <li class=md-nav__item> <a href=#775 class=md-nav__link> <span class=md-ellipsis> 7.7.5. 训练模型 </span> </a> </li> <li class=md-nav__item> <a href=#776 class=md-nav__link> <span class=md-ellipsis> 7.7.6. 小结 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=_1>现代卷积神经网络<a class=headerlink href=#_1 title="Permanent link">&para;</a></h1> <p>上一章我们介绍了卷积神经网络的基本原理，本章将介绍现代的卷积神经网络架构，许多现代卷积神经网络的研究都是建立在这一章的基础上的。 在本章中的每一个模型都曾一度占据主导地位，其中许多模型都是ImageNet竞赛的优胜者。ImageNet竞赛自2010年以来，一直是计算机视觉中监督学习进展的指向标。</p> <p>这些模型包括：</p> <ul> <li>AlexNet。它是第一个在大规模视觉竞赛中击败传统计算机视觉模型的大型神经网络；</li> <li>使用重复块的网络（VGG）。它利用许多重复的神经网络块；</li> <li>网络中的网络（NiN）。它重复使用由卷积层和<span class=arithmatex>\(1\times 1\)</span>卷积层（用来代替全连接层）来构建深层网络;</li> <li>含并行连结的网络（GoogLeNet）。它使用并行连结的网络，通过不同窗口大小的卷积层和最大汇聚层来并行抽取信息；</li> <li>残差网络（ResNet）。它通过残差块构建跨层的数据通道，是计算机视觉中最流行的体系架构；</li> <li>稠密连接网络（DenseNet）。它的计算成本很高，但给我们带来了更好的效果。</li> </ul> <p>虽然深度神经网络的概念非常简单——将神经网络堆叠在一起。但由于不同的网络架构和超参数选择，这些神经网络的性能会发生很大变化。 本章介绍的神经网络是将人类直觉和相关数学见解结合后，经过大量研究试错后的结晶。 我们会按时间顺序介绍这些模型，在追寻历史的脉络的同时，帮助培养对该领域发展的直觉。这将有助于研究开发自己的架构。 例如，本章介绍的批量规范化（batch normalization）和残差网络（ResNet）为设计和训练深度神经网络提供了重要思想指导。</p> <h2 id=71-alexnet>7.1. 深度卷积神经网络（AlexNet）<a class=headerlink href=#71-alexnet title="Permanent link">&para;</a></h2> <p>当人们和机器学习研究人员交谈时，会发现机器学习研究人员相信机器学习既重要又美丽：优雅的理论去证明各种模型的性质。机器学习是一个正在蓬勃发展、严谨且非常有用的领域。然而，当人们和计算机视觉研究人员交谈，会听到一个完全不同的故事。计算机视觉研究人员会告诉一个诡异事实————推动领域进步的是数据特征，而不是学习算法。计算机视觉研究人员相信，从对最终模型精度的影响来说，更大或更干净的数据集、或是稍微改进的特征提取，比任何学习算法带来的进步要大得多。</p> <h3 id=711>7.1.1. 学习表征<a class=headerlink href=#711 title="Permanent link">&para;</a></h3> <p>另一种预测这个领域发展的方法————观察图像特征的提取方法。在2012年前，图像特征都是机械地计算出来的。事实上，设计一套新的特征函数、改进结果，并撰写论文是盛极一时的潮流。SIFT (Lowe, 2004)、SURF (Bay et al., 2006)、HOG（定向梯度直方图） (Dalal and Triggs, 2005)、bags of visual words和类似的特征提取方法占据了主导地位。</p> <p>另一组研究人员，包括Yann LeCun、Geoff Hinton、Yoshua Bengio、Andrew Ng、Shun ichi Amari和Juergen Schmidhuber，想法则与众不同：他们认为特征本身应该被学习。此外，他们还认为，在合理地复杂性前提下，特征应该由多个共同学习的神经网络层组成，每个层都有可学习的参数。在机器视觉中，最底层可能检测边缘、颜色和纹理。事实上，Alex Krizhevsky、Ilya Sutskever和Geoff Hinton提出了一种新的卷积神经网络变体AlexNet。在2012年ImageNet挑战赛中取得了轰动一时的成绩。AlexNet以Alex Krizhevsky的名字命名，他是论文 (Krizhevsky et al., 2012)的第一作者。</p> <p>有趣的是，在网络的最底层，模型学习到了一些类似于传统滤波器的特征抽取器。 图7.1.1是从AlexNet论文 (Krizhevsky et al., 2012)复制的，描述了底层图像特征。</p> <p>AlexNet的更高层建立在这些底层表示的基础上，以表示更大的特征，如眼睛、鼻子、草叶等等。而更高的层可以检测整个物体，如人、飞机、狗或飞盘。最终的隐藏神经元可以学习图像的综合表示，从而使属于不同类别的数据易于区分。尽管一直有一群执着的研究者不断钻研，试图学习视觉数据的逐级表征，然而很长一段时间里这些尝试都未有突破。深度卷积神经网络的突破出现在2012年。突破可归因于两个关键因素。</p> <h4 id=7111>7.1.1.1 缺少的成分：数据<a class=headerlink href=#7111 title="Permanent link">&para;</a></h4> <p>包含许多特征的深度模型需要大量的有标签数据，才能显著优于基于凸优化的传统方法（如线性方法和核方法）。 然而，限于早期计算机有限的存储和90年代有限的研究预算，大部分研究只基于小的公开数据集。例如，不少研究论文基于加州大学欧文分校（UCI）提供的若干个公开数据集，其中许多数据集只有几百至几千张在非自然环境下以低分辨率拍摄的图像。这一状况在2010年前后兴起的大数据浪潮中得到改善。2009年，ImageNet数据集发布，并发起ImageNet挑战赛：要求研究人员从100万个样本中训练模型，以区分1000个不同类别的对象。ImageNet数据集由斯坦福教授李飞飞小组的研究人员开发，利用谷歌图像搜索（Google Image Search）对每一类图像进行预筛选，并利用亚马逊众包（Amazon Mechanical Turk）来标注每张图片的相关类别。这种规模是前所未有的。这项被称为ImageNet的挑战赛推动了计算机视觉和机器学习研究的发展，挑战研究人员确定哪些模型能够在更大的数据规模下表现最好。</p> <h4 id=7112>7.1.1.2 缺少的成分：硬件<a class=headerlink href=#7112 title="Permanent link">&para;</a></h4> <p>深度学习对计算资源要求很高，训练可能需要数百个迭代轮数，每次迭代都需要通过代价高昂的许多线性代数层传递数据。这也是为什么在20世纪90年代至21世纪初，优化凸目标的简单算法是研究人员的首选。然而，用GPU训练神经网络改变了这一格局。图形处理器（Graphics Processing Unit，GPU）早年用来加速图形处理，使电脑游戏玩家受益。GPU可优化高吞吐量的 矩阵和向量乘法，从而服务于基本的图形任务。幸运的是，这些数学运算与卷积层的计算惊人地相似。由此，英伟达（NVIDIA）和ATI已经开始为通用计算操作优化gpu，甚至把它们作为通用GPU（general-purpose GPUs，GPGPU）来销售。</p> <p>那么GPU比CPU强在哪里呢？</p> <p>首先，我们深度理解一下中央处理器（Central Processing Unit，CPU）的核心。 CPU的每个核心都拥有高时钟频率的运行能力，和高达数MB的三级缓存（L3Cache）。 它们非常适合执行各种指令，具有分支预测器、深层流水线和其他使CPU能够运行各种程序的功能。 然而，这种明显的优势也是它的致命弱点：通用核心的制造成本非常高。 它们需要大量的芯片面积、复杂的支持结构（内存接口、内核之间的缓存逻辑、高速互连等等），而且它们在任何单个任务上的性能都相对较差。 现代笔记本电脑最多有4核，即使是高端服务器也很少超过64核，因为它们的性价比不高。</p> <p>相比于CPU，GPU由10-1000个个小的处理单元组成（NVIDIA、ATI、ARM和其他芯片供应商之间的细节稍有不同），通常被分成更大的组（NVIDIA称之为warps）。 虽然每个GPU核心都相对较弱，有时甚至以低于1GHz的时钟频率运行，但庞大的核心数量使GPU比CPU快几个数量级。 例如，NVIDIA最近一代的Ampere GPU架构为每个芯片提供了高达312 TFlops的浮点性能，而CPU的浮点性能到目前为止还没有超过1 TFlops。 之所以有如此大的差距，原因其实很简单：首先，功耗往往会随时钟频率呈二次方增长。 对于一个CPU核心，假设它的运行速度比GPU快4倍，但可以使用16个GPU核代替，那么GPU的综合性能就是CPU的16*&frac14;=4倍。 其次，GPU内核要简单得多，这使得它们更节能。 此外，深度学习中的许多操作需要相对较高的内存带宽，而GPU拥有10倍于CPU的带宽。</p> <p>回到2012年的重大突破，当Alex Krizhevsky和Ilya Sutskever实现了可以在GPU硬件上运行的深度卷积神经网络时，一个重大突破出现了。他们意识到卷积神经网络中的计算瓶颈：卷积和矩阵乘法，都是可以在硬件上并行化的操作。 于是，他们使用两个显存为3GB的NVIDIA GTX580 GPU实现了快速卷积运算。他们的创新cuda-convnet几年来它一直是行业标准，并推动了深度学习热潮。</p> <h3 id=712-alexnet>7.1.2. AlexNet<a class=headerlink href=#712-alexnet title="Permanent link">&para;</a></h3> <p>2012年，AlexNet横空出世。它首次证明了学习到的特征可以超越手工设计的特征。它一举打破了计算机视觉研究的现状。 AlexNet使用了8层卷积神经网络，并以很大的优势赢得了2012年ImageNet图像识别挑战赛。</p> <p>AlexNet和LeNet的架构非常相似，如 图7.1.2所示。 注意，本书在这里提供的是一个稍微精简版本的AlexNet，去除了当年需要两个小型GPU同时运算的设计特点。</p> <p><img alt=alexnet src=../../../../../09.AI/NOTE-D2L/CH7-MODERN-CNN/alexnet.svg> LeNet vs AlexNet</p> <p>AlexNet和LeNet的设计理念非常相似，但也存在显著差异。</p> <p>AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。</p> <p>AlexNet使用ReLU而不是sigmoid作为其激活函数。</p> <p>下面的内容将深入研究AlexNet的细节。</p> <h4 id=7121>7.1.2.1 模型设计<a class=headerlink href=#7121 title="Permanent link">&para;</a></h4> <h4 id=7122>7.1.2.2 激活函数<a class=headerlink href=#7122 title="Permanent link">&para;</a></h4> <p>此外，AlexNet将sigmoid激活函数改为更简单的ReLU激活函数。 一方面，ReLU激活函数的计算更简单，它不需要如sigmoid激活函数那般复杂的求幂运算。 另一方面，当使用不同的参数初始化方法时，ReLU激活函数使训练模型更加容易。 当sigmoid激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数。 相反，ReLU激活函数在正区间的梯度总是1。 因此，如果模型参数没有正确初始化，sigmoid函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。</p> <h4 id=7123>7.1.2.3 容量控制和预处理<a class=headerlink href=#7123 title="Permanent link">&para;</a></h4> <p>AlexNet通过暂退法（ 4.6节）控制全连接层的模型复杂度，而LeNet只使用了权重衰减。 为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色。 这使得模型更健壮，更大的样本量有效地减少了过拟合。 在 13.1节中更详细地讨论数据扩增。</p> <h3 id=713>7.1.3. 读取数据集<a class=headerlink href=#713 title="Permanent link">&para;</a></h3> <h3 id=714-alexnet>7.1.4. 训练AlexNet<a class=headerlink href=#714-alexnet title="Permanent link">&para;</a></h3> <h3 id=715>7.1.5. 小结<a class=headerlink href=#715 title="Permanent link">&para;</a></h3> <ul> <li>AlexNet的架构与LeNet相似，但使用了更多的卷积层和更多的参数来拟合大规模的ImageNet数据集。</li> <li>今天，AlexNet已经被更有效的架构所超越，但它是**从浅层网络到深层网络**的关键一步。</li> <li>尽管AlexNet的代码只比LeNet多出几行，但学术界花了很多年才接受**深度学习**这一概念，并应用其出色的实验结果。这也是由于缺乏有效的计算工具。</li> <li><strong>Dropout</strong>、**ReLU**和**预处理**是提升计算机视觉任务性能的其他关键步骤。</li> </ul> <h2 id=72-vgg>7.2. 使用块的网络（VGG）<a class=headerlink href=#72-vgg title="Permanent link">&para;</a></h2> <p>虽然AlexNet证明深层神经网络卓有成效，但它没有提供一个通用的模板来指导后续的研究人员设计新的网络。 在下面的几个章节中，我们将介绍一些常用于设计深层神经网络的启发式概念。</p> <p>与芯片设计中工程师从放置晶体管到逻辑元件再到逻辑块的过程类似，神经网络架构的设计也逐渐变得更加抽象。研究人员开始从单个神经元的角度思考问题，发展到整个层，现在又转向块，重复层的模式。</p> <p>使用块的想法首先出现在牛津大学的视觉几何组（visual geometry group）的VGG网络中。通过使用循环和子程序，可以很容易地在任何现代深度学习框架的代码中实现这些重复的架构。</p> <h3 id=721-vgg>7.2.1. VGG块<a class=headerlink href=#721-vgg title="Permanent link">&para;</a></h3> <p>**经典卷积神经网络的基本组成部分**是下面的这个序列：</p> <ul> <li> <p>带填充以保持分辨率的卷积层；</p> </li> <li> <p>非线性激活函数，如ReLU；</p> </li> <li> <p>汇聚层，如最大汇聚层。</p> </li> </ul> <p>而一个VGG块与之类似，由一系列卷积层组成，后面再加上用于空间下采样的最大汇聚层。在最初的VGG论文中 (Simonyan and Zisserman, 2014)，作者使用了带有3x3卷积核、填充为1（保持高度和宽度）的卷积层，和带有2x2汇聚窗口、步幅为2（每个块后的分辨率减半）的最大汇聚层。在下面的代码中，我们定义了一个名为vgg_block的函数来实现一个VGG块。</p> <h3 id=722-vgg>7.2.2. VGG网络<a class=headerlink href=#722-vgg title="Permanent link">&para;</a></h3> <p>与AlexNet、LeNet一样，VGG网络可以分为两部分：第一部分主要由卷积层和汇聚层组成，第二部分由全连接层组成。如 图7.2.1中所示。</p> <p><img alt=vgg src=../../../../../09.AI/NOTE-D2L/CH7-MODERN-CNN/vgg.svg></p> <h3 id=723>7.2.3. 训练模型<a class=headerlink href=#723 title="Permanent link">&para;</a></h3> <h3 id=724>7.2.4. 小结<a class=headerlink href=#724 title="Permanent link">&para;</a></h3> <ul> <li>VGG-11使用**可复用的卷积块**构造网络。不同的VGG模型可通过每个块中**卷积层数量**和**输出通道数量**的差异来定义。</li> <li>块的使用导致网络定义的非常简洁。<strong>使用块可以有效地设计复杂的网络。</strong></li> <li>在VGG论文中，Simonyan和Ziserman尝试了各种架构。<strong>特别是他们发现深层且窄的卷积（即3x3）比较浅层且宽的卷积更有效。</strong></li> </ul> <h2 id=73-nin>7.3. 网络中的网络（NiN）<a class=headerlink href=#73-nin title="Permanent link">&para;</a></h2> <p>LeNet、AlexNet和VGG都有一个共同的设计模式：通过一系列的卷积层与汇聚层来提取空间结构特征；然后通过全连接层对特征的表征进行处理。 AlexNet和VGG对LeNet的改进主要在于如何扩大和加深这两个模块。 或者，可以想象在这个过程的早期使用全连接层。然而，<strong>如果使用了全连接层，可能会完全放弃表征的空间结构。</strong> 网络中的网络（NiN）提供了一个非常简单的解决方案：<strong>在每个像素的通道上分别使用多层感知机</strong> (Lin et al., 2013)</p> <h3 id=731-nin>7.3.1. NiN块<a class=headerlink href=#731-nin title="Permanent link">&para;</a></h3> <p>回想一下，卷积层的输入和输出由四维张量组成，张量的每个轴分别对应样本、通道、高度和宽度。 另外，全连接层的输入和输出通常是分别对应于样本和特征的二维张量。 NiN的想法是在每个像素位置（针对每个高度和宽度）应用一个全连接层。 如果我们将权重连接到每个空间位置，我们可以将其视为1x1卷积层（如 6.4节中所述），或作为在每个像素位置上独立作用的全连接层。 从另一个角度看，即将空间维度中的每个像素视为单个样本，将通道维度视为不同特征（feature）。</p> <p><img alt=nin src=../../../../../09.AI/NOTE-D2L/CH7-MODERN-CNN/nin.svg></p> <h3 id=732-nin>7.3.2. NiN模型<a class=headerlink href=#732-nin title="Permanent link">&para;</a></h3> <p>最初的NiN网络是在AlexNet后不久提出的，显然从中得到了一些启示。 NiN使用窗口形状为11x11、5x5和3x3的卷积层，输出通道数量与AlexNet中的相同。 每个NiN块后有一个最大汇聚层，汇聚窗口形状为 ，步幅为2。</p> <p>NiN和AlexNet之间的一个显著区别是NiN完全取消了全连接层。 相反，NiN使用一个NiN块，其输出通道数等于标签类别的数量。最后放一个全局平均汇聚层（global average pooling layer），生成一个对数几率 （logits）。NiN设计的一个优点是，它显著减少了模型所需参数的数量。然而，在实践中，这种设计有时会增加训练模型的时间。</p> <h3 id=733>7.3.3. 训练模型<a class=headerlink href=#733 title="Permanent link">&para;</a></h3> <h3 id=734>7.3.4. 小结<a class=headerlink href=#734 title="Permanent link">&para;</a></h3> <ul> <li>NiN使用由一个卷积层和多个1x1卷积层组成的块。该块可以在卷积神经网络中使用，以允许更多的每像素非线性。</li> <li>NiN去除了容易造成过拟合的全连接层，将它们替换为全局平均汇聚层（即在所有位置上进行求和）。该汇聚层通道数量为所需的输出数量（例如，Fashion-MNIST的输出为10）。</li> <li>移除全连接层可减少过拟合，同时显著减少NiN的参数。</li> <li>NiN的设计影响了许多后续卷积神经网络的设计。</li> </ul> <h2 id=74-googlenet>7.4. 含并行连结的网络（GoogLeNet）<a class=headerlink href=#74-googlenet title="Permanent link">&para;</a></h2> <p>在2014年的ImageNet图像识别挑战赛中，一个名叫GoogLeNet (Szegedy et al., 2015)的网络架构大放异彩。 <strong>GoogLeNet吸收了NiN中串联网络的思想，</strong> 并在此基础上做了改进。 <strong>这篇论文的一个重点是解决了什么样大小的卷积核最合适的问题。</strong> 毕竟，以前流行的网络使用小到1x1，大到11x11的卷积核。 本文的一个观点是，有时使用不同大小的卷积核组合是有利的。 本节将介绍一个稍微简化的GoogLeNet版本：我们省略了一些为稳定训练而添加的特殊特性，现在有了更好的训练方法，这些特性不是必要的。</p> <h3 id=741-inception>7.4.1. Inception块<a class=headerlink href=#741-inception title="Permanent link">&para;</a></h3> <p><img alt=inception src=../../../../../09.AI/NOTE-D2L/CH7-MODERN-CNN/inception.svg></p> <h3 id=742-googlenet>7.4.2. GoogLeNet模型<a class=headerlink href=#742-googlenet title="Permanent link">&para;</a></h3> <p><img alt=inception-full-90 src=../../../../../09.AI/NOTE-D2L/CH7-MODERN-CNN/inception-full-90.svg></p> <h3 id=743>7.4.3. 训练模型<a class=headerlink href=#743 title="Permanent link">&para;</a></h3> <h3 id=744>7.4.4. 小结<a class=headerlink href=#744 title="Permanent link">&para;</a></h3> <ul> <li> <p>inception块相当于一个有4条路径的子网络。它通过不同窗口形状的卷积层和最大汇聚层来并行抽取信息，并使用1x1卷积层减少每像素级别上的通道维数从而降低模型复杂度。</p> </li> <li> <p>GoogLeNet将多个设计精细的Inception块与其他层（卷积层、全连接层）串联起来。其中Inception块的通道数分配之比是在ImageNet数据集上通过大量的实验得来的。</p> </li> <li> <p>GoogLeNet和它的后继者们一度是ImageNet上最有效的模型之一：它以较低的计算复杂度提供了类似的测试精度。</p> </li> </ul> <h2 id=75>7.5. 批量规范化<a class=headerlink href=#75 title="Permanent link">&para;</a></h2> <p>训练深层神经网络是十分困难的，特别是在较短的时间内使他们收敛更加棘手。 本节将介绍批量规范化（batch normalization） (Ioffe and Szegedy, 2015)，这是一种流行且有效的技术，可持续加速深层网络的收敛速度。 再结合在 7.6节中将介绍的残差块，批量规范化使得研究人员能够训练100层以上的网络。</p> <h3 id=751>7.5.1. 训练深层网络<a class=headerlink href=#751 title="Permanent link">&para;</a></h3> <p>为什么需要批量规范化层呢？让我们来回顾一下训练神经网络时出现的一些实际挑战。</p> <p>首先，数据预处理的方式通常会对最终结果产生巨大影响。 回想一下我们应用多层感知机来预测房价的例子（ 4.10节）。 使用真实数据时，我们的第一步是标准化输入特征，使其平均值为0，方差为1。 直观地说，这种标准化可以很好地与我们的优化器配合使用，因为它可以将参数的量级进行统一。</p> <p>第二，对于典型的多层感知机或卷积神经网络。当我们训练时，中间层中的变量（例如，多层感知机中的仿射变换输出）可能具有更广的变化范围：不论是沿着从输入到输出的层，跨同一层中的单元，或是随着时间的推移，模型参数的随着训练更新变幻莫测。 批量规范化的发明者非正式地假设，这些变量分布中的这种偏移可能会阻碍网络的收敛。 直观地说，我们可能会猜想，如果一个层的可变值是另一层的100倍，这可能需要对学习率进行补偿调整。</p> <p>第三，更深层的网络很复杂，容易过拟合。 这意味着正则化变得更加重要。</p> <p>批量规范化应用于单个可选层（也可以应用到所有层），其原理如下：在每次训练迭代中，我们首先规范化输入，即通过减去其均值并除以其标准差，其中两者均基于当前小批量处理。 接下来，我们应用比例系数和比例偏移。 <strong>正是由于这个基于批量统计的标准化，才有了批量规范化的名称。</strong></p> <p>从形式上来说，用<span class=arithmatex>\(\mathbf{x} \in \mathcal{B}\)</span>表示一个来自小批量<span class=arithmatex>\(\mathcal{B}\)</span>的输入，批量规范化<span class=arithmatex>\(\mathrm{BN}\)</span>根据以下表达式转换<span class=arithmatex>\(\mathbf{x}\)</span>：</p> <div class=arithmatex>\[\mathrm{BN}(\mathbf{x}) = {\gamma} \odot \frac{\mathbf{x} - \hat{{\mu}}_\mathcal{B}}{\hat{{\sigma}}_\mathcal{B}} + {\beta}.\]</div> <p><span class=arithmatex>\(\hat{{\mu}}_\mathcal{B}\)</span>是小批量<span class=arithmatex>\(\mathcal{B}\)</span>的样本均值，<span class=arithmatex>\(\hat{{\sigma}}_\mathcal{B}\)</span>是小批量<span class=arithmatex>\(\mathcal{B}\)</span>的样本标准差。</p> <p>由于单位方差（与其他一些魔法数）是一个主观的选择，因此我们通常包含 <em>拉伸参数</em>（scale）<span class=arithmatex>\({\gamma}\)</span>和 <em>偏移参数</em>（shift）<span class=arithmatex>\({\beta}\)</span>，它们的形状与<span class=arithmatex>\(\mathbf{x}\)</span>相同。 请注意，<span class=arithmatex>\({\gamma}\)</span>和<span class=arithmatex>\({\beta}\)</span>是需要与其他模型参数一起学习的参数。</p> <p>由于在训练过程中，中间层的变化幅度不能过于剧烈，而批量规范化将每一层主动居中，并将它们重新调整为给定的平均值和大小（通过<span class=arithmatex>\(\hat{{\mu}}_\mathcal{B}\)</span>和<span class=arithmatex>\({\hat{{\sigma}}_\mathcal{B}}\)</span>）。</p> <p>从形式上来看，我们计算出中的<span class=arithmatex>\(\hat{{\mu}}_\mathcal{B}\)</span>和<span class=arithmatex>\({\hat{{\sigma}}_\mathcal{B}}\)</span>，如下所示：</p> <div class=arithmatex>\[\begin{aligned} \hat{{\mu}}_\mathcal{B} &amp;= \frac{1}{|\mathcal{B}|} \sum_{\mathbf{x} \in \mathcal{B}} \mathbf{x},\\ \hat{{\sigma}}_\mathcal{B}^2 &amp;= \frac{1}{|\mathcal{B}|} \sum_{\mathbf{x} \in \mathcal{B}} (\mathbf{x} - \hat{{\mu}}_{\mathcal{B}})^2 + \epsilon.\end{aligned}\]</div> <p>请注意，我们在方差估计值中添加一个小的常量<span class=arithmatex>\(\epsilon &gt; 0\)</span>，以确保我们永远不会尝试除以零，即使在经验方差估计值可能消失的情况下也是如此。估计值<span class=arithmatex>\(\hat{{\mu}}_\mathcal{B}\)</span>和<span class=arithmatex>\({\hat{{\sigma}}_\mathcal{B}}\)</span>通过使用平均值和方差的噪声（noise）估计来抵消缩放问题。 乍看起来，这种噪声是一个问题，而事实上它是有益的。</p> <p>事实证明，这是深度学习中一个反复出现的主题。 由于尚未在理论上明确的原因，优化中的各种噪声源通常会导致更快的训练和较少的过拟合：这种变化似乎是正则化的一种形式。 在一些初步研究中将批量规范化的性质与贝叶斯先验相关联。 这些理论揭示了为什么批量规范化最适应<span class=arithmatex>\(50 \sim 100\)</span>范围中的中等批量大小的难题。</p> <p>另外，批量规范化层在”训练模式“（通过小批量统计数据规范化）和“预测模式”（通过数据集统计规范化）中的功能不同。**在训练过程中，我们无法得知使用整个数据集来估计平均值和方差，所以只能根据每个小批次的平均值和方差不断训练模型。 而在预测模式下，可以根据整个数据集精确计算批量规范化所需的平均值和方**差。</p> <p>现在，我们了解一下批量规范化在实践中是如何工作的。</p> <h3 id=752>7.5.2. 批量规范化层<a class=headerlink href=#752 title="Permanent link">&para;</a></h3> <p>回想一下，批量规范化和其他层之间的一个关键区别是，由于批量规范化在完整的小批量上运行，因此我们不能像以前在引入其他层时那样忽略批量大小。 我们在下面讨论这两种情况：全连接层和卷积层，他们的批量规范化实现略有不同。</p> <h4 id=7521>7.5.2.1 全连接层<a class=headerlink href=#7521 title="Permanent link">&para;</a></h4> <p><strong>通常，我们将批量规范化层置于全连接层中的仿射变换和激活函数之间。</strong> 设全连接层的输入为x，权重参数和偏置参数分别为<span class=arithmatex>\(\mathbf{W}\)</span>和<span class=arithmatex>\(\mathbf{b}\)</span>，激活函数为<span class=arithmatex>\(\phi\)</span>，批量规范化的运算符为<span class=arithmatex>\(\mathrm{BN}\)</span>。 那么，使用批量规范化的全连接层的输出的计算详情如下：</p> <div class=arithmatex>\[\mathbf{h} = \phi(\mathrm{BN}(\mathbf{W}\mathbf{x} + \mathbf{b}) ).\]</div> <p>回想一下，均值和方差是在应用变换的"相同"小批量上计算的。</p> <h4 id=7522>7.5.2.2 卷积层<a class=headerlink href=#7522 title="Permanent link">&para;</a></h4> <p><strong>同样，对于卷积层，我们可以在卷积层之后和非线性激活函数之前应用批量规范化。</strong> <strong>当卷积有多个输出通道时，我们需要对这些通道的“每个”输出执行批量规范化，每个通道都有自己的拉伸（scale）和偏移（shift）参数，这两个参数都是标量。</strong> 假设我们的小批量包含<span class=arithmatex>\(m\)</span>个样本，并且对于每个通道，卷积的输出具有高度<span class=arithmatex>\(p\)</span>和宽度<span class=arithmatex>\(q\)</span>。 那么对于卷积层，我们在每个输出通道的<span class=arithmatex>\(m \cdot p \cdot q\)</span>个元素上同时执行每个批量规范化。 因此，在计算平均值和方差时，我们会收集所有空间位置的值，然后在给定通道内应用相同的均值和方差，以便在每个空间位置对值进行规范化。</p> <h4 id=7523>7.5.2.3 预测过程中的批量规范化<a class=headerlink href=#7523 title="Permanent link">&para;</a></h4> <p>正如我们前面提到的，批量规范化在训练模式和预测模式下的行为通常不同。 首先，将训练好的模型用于预测时，我们不再需要样本均值中的噪声以及在微批次上估计每个小批次产生的样本方差了。 其次，例如，我们可能需要使用我们的模型对逐个样本进行预测。 一种常用的方法是通过移动平均估算整个训练数据集的样本均值和方差，并在预测时使用它们得到确定的输出。 可见，和暂退法一样，批量规范化层在训练模式和预测模式下的计算结果也是不一样的。</p> <h3 id=753>7.5.3. 从零实现<a class=headerlink href=#753 title="Permanent link">&para;</a></h3> <h3 id=754-lenet>7.5.4. 使用批量规范化层的 LeNet<a class=headerlink href=#754-lenet title="Permanent link">&para;</a></h3> <h3 id=755>7.5.5. 简明实现<a class=headerlink href=#755 title="Permanent link">&para;</a></h3> <h3 id=756>7.5.6. 争议<a class=headerlink href=#756 title="Permanent link">&para;</a></h3> <p>直观地说，批量规范化被认为可以使优化更加平滑。 然而，我们必须小心区分直觉和对我们观察到的现象的真实解释。 回想一下，我们甚至不知道简单的神经网络（多层感知机和传统的卷积神经网络）为什么如此有效。 即使在暂退法和权重衰减的情况下，它们仍然非常灵活，因此无法通过常规的学习理论泛化保证来解释它们是否能够泛化到看不见的数据。</p> <p>在提出批量规范化的论文中，作者除了介绍了其应用，还解释了其原理：通过减少*内部协变量偏移*（internal covariate shift）。 据推测，作者所说的*内部协变量转移*类似于上述的投机直觉，即变量值的分布在训练过程中会发生变化。 然而，这种解释有两个问题： 1、这种偏移与严格定义的*协变量偏移*（covariate shift）非常不同，所以这个名字用词不当； 2、这种解释只提供了一种不明确的直觉，但留下了一个有待后续挖掘的问题：为什么这项技术如此有效？ 本书旨在传达实践者用来发展深层神经网络的直觉。 然而，重要的是将这些指导性直觉与既定的科学事实区分开来。 最终，当你掌握了这些方法，并开始撰写自己的研究论文时，你会希望清楚地区分技术和直觉。</p> <p>随着批量规范化的普及，*内部协变量偏移*的解释反复出现在技术文献的辩论，特别是关于“如何展示机器学习研究”的更广泛的讨论中。 Ali Rahimi在接受2017年NeurIPS大会的“接受时间考验奖”（Test of Time Award）时发表了一篇令人难忘的演讲。他将“内部协变量转移”作为焦点，将现代深度学习的实践比作炼金术。 他对该示例进行了详细回顾 :cite:<code>Lipton.Steinhardt.2018</code>，概述了机器学习中令人不安的趋势。 此外，一些作者对批量规范化的成功提出了另一种解释：在某些方面，批量规范化的表现出与原始论文 :cite:<code>Santurkar.Tsipras.Ilyas.ea.2018</code>中声称的行为是相反的。</p> <p>然而，与机器学习文献中成千上万类似模糊的说法相比，内部协变量偏移没有更值得批评。 很可能，它作为这些辩论的焦点而产生共鸣，要归功于目标受众对它的广泛认可。 批量规范化已经被证明是一种不可或缺的方法。它适用于几乎所有图像分类器，并在学术界获得了数万引用。</p> <h3 id=757>7.5.7. 小结<a class=headerlink href=#757 title="Permanent link">&para;</a></h3> <ul> <li>在模型训练过程中，<strong>批量规范化**利用**小批量的均值和标准差</strong>，不断**调整**神经网络的**中间输出**，使整个神经网络各层的**中间输出值更加稳定**。</li> <li>批量规范化在全连接层和卷积层的使用略有不同。</li> <li>批量规范化层和暂退层一样，在训练模式和预测模式下计算不同。</li> <li>批量规范化有许多有益的副作用，主要是正则化。另一方面，”减少内部协变量偏移“的原始动机似乎不是一个有效的解释。</li> </ul> <h2 id=76-resnet>7.6. 残差网络（ResNet）<a class=headerlink href=#76-resnet title="Permanent link">&para;</a></h2> <p>随着我们设计越来越深的网络，深刻理解“新添加的层如何提升神经网络的性能”变得至关重要。更重要的是设计网络的能力，在这种网络中，添加层会使网络更具表现力， 为了取得质的突破，我们需要一些数学基础知识。</p> <h3 id=761>7.6.1. 函数类<a class=headerlink href=#761 title="Permanent link">&para;</a></h3> <p>首先，假设有一类特定的神经网络架构<span class=arithmatex>\(\mathcal{F}\)</span>，它包括学习速率和其他超参数设置。 对于所有<span class=arithmatex>\(f \in \mathcal{F}\)</span>，存在一些参数集（例如权重和偏置），这些参数可以通过在合适的数据集上进行训练而获得。 现在假设<span class=arithmatex>\(f^*\)</span>是我们真正想要找到的函数，如果是<span class=arithmatex>\(f^* \in \mathcal{F}\)</span>，那我们可以轻而易举的训练得到它，但通常我们不会那么幸运。 相反，我们将尝试找到一个函数<span class=arithmatex>\(f^*_\mathcal{F}\)</span>，这是我们在<span class=arithmatex>\(\mathcal{F}\)</span>中的最佳选择。 例如，给定一个具有<span class=arithmatex>\(\mathbf{X}\)</span>特性和<span class=arithmatex>\(\mathbf{y}\)</span>标签的数据集，我们可以尝试通过解决以下优化问题来找到它：</p> <div class=arithmatex>\[f^*_\mathcal{F} := \mathop{\mathrm{argmin}}_f L(\mathbf{X}, \mathbf{y}, f) \text{ subject to } f \in \mathcal{F}.\]</div> <p>那么，怎样得到更近似真正<span class=arithmatex>\(f^*\)</span>的函数呢？ 唯一合理的可能性是，我们需要设计一个更强大的架构<span class=arithmatex>\(\mathcal{F}'\)</span>。 换句话说，我们预计<span class=arithmatex>\(f^*_{\mathcal{F}'}\)</span>比<span class=arithmatex>\(f^*_{\mathcal{F}}\)</span>“更近似”。 然而，如果<span class=arithmatex>\(\mathcal{F} \not\subseteq \mathcal{F}'\)</span>，则无法保证新的体系“更近似”。 事实上，<span class=arithmatex>\(f^*_{\mathcal{F}'}\)</span>可能更糟： 如图所示，对于非嵌套函数（non-nested function）类，较复杂的函数类并不总是向“真”函数<span class=arithmatex>\(f^*\)</span>靠拢（复杂度由<span class=arithmatex>\(\mathcal{F}_1\)</span>向<span class=arithmatex>\(\mathcal{F}_6\)</span>递增）。 在下图的左边，虽然<span class=arithmatex>\(\mathcal{F}_3\)</span>比<span class=arithmatex>\(\mathcal{F}_1\)</span>更接近<span class=arithmatex>\(f^*\)</span>，但<span class=arithmatex>\(\mathcal{F}_6\)</span>却离的更远了。 相反对于图右侧的嵌套函数（nested function）类<span class=arithmatex>\(\mathcal{F}_1 \subseteq \ldots \subseteq \mathcal{F}_6\)</span>，我们可以避免上述问题。</p> <p><img alt=functionclasses src=../../../../../09.AI/NOTE-D2L/CH7-MODERN-CNN/functionclasses.svg></p> <p>因此，<strong>只有当较复杂的函数类包含较小的函数类时，我们才能确保提高它们的性能。</strong> 对于深度神经网络，如果我们能将新添加的层训练成*恒等映射*（identity function）<span class=arithmatex>\(f(\mathbf{x}) = \mathbf{x}\)</span>，新模型和原模型将同样有效。 同时，由于新模型可能得出更优的解来拟合训练数据集，因此添加层似乎更容易降低训练误差。</p> <p>针对这一问题，何恺明等人提出了*残差网络*（ResNet）的设计思想。 它在2015年的ImageNet图像识别挑战赛夺魁，并深刻影响了后来的深度神经网络的设计。 残差网络的核心思想是：<strong>每个附加层都应该更容易地包含原始函数作为其元素之一</strong>。 于是，<em>残差块</em>（residual blocks）便诞生了，这个设计对如何建立深层神经网络产生了深远的影响。 凭借它，ResNet赢得了2015年ImageNet大规模视觉识别挑战赛。x</p> <h3 id=762>7.6.2. 残差块<a class=headerlink href=#762 title="Permanent link">&para;</a></h3> <p>让我们聚焦于神经网络局部：如图 (配图-残差块)所示，假设我们的原始输入为<span class=arithmatex>\(x\)</span>，而希望学出的理想映射为<span class=arithmatex>\(f(\mathbf{x})\)</span>（作为 (配图-残差块)上方激活函数的输入）。 (配图-残差块)左图虚线框中的部分需要直接拟合出该映射<span class=arithmatex>\(f(\mathbf{x})\)</span>，而右图虚线框中的部分则需要拟合出残差映射<span class=arithmatex>\(f(\mathbf{x}) - \mathbf{x}\)</span>。 残差映射在现实中往往更容易优化。 以本节开头提到的恒等映射作为我们希望学出的理想映射<span class=arithmatex>\(f(\mathbf{x})\)</span>，我们只需将 (配图-残差块)中右图虚线框内上方的加权运算（如仿射）的权重和偏置参数设成0，那么<span class=arithmatex>\(f(\mathbf{x})\)</span>即为恒等映射。 实际中，当理想映射<span class=arithmatex>\(f(\mathbf{x})\)</span>极接近于恒等映射时，残差映射也易于捕捉恒等映射的细微波动。 (配图-残差块)右图是ResNet的基础架构--<em>残差块</em>（residual block）。 <strong>在残差块中，输入可通过跨层数据线路更快地向前传播。</strong></p> <p><img alt="A regular block (left) and a residual block (right)." src=../../../../../09.AI/NOTE-D2L/CH7-MODERN-CNN/residual-block.svg> 残差块</p> <p>ResNet沿用了VGG完整的<span class=arithmatex>\(3\times 3\)</span>卷积层设计。 残差块里首先有2个有相同输出通道数的<span class=arithmatex>\(3\times 3\)</span>卷积层。 每个卷积层后接一个批量规范化层和ReLU激活函数。 然后我们通过跨层数据通路，跳过这2个卷积运算，将输入直接加在最后的ReLU激活函数前。 这样的设计要求2个卷积层的输出与输入形状一样，从而使它们可以相加。 如果想改变通道数，就需要引入一个额外的<span class=arithmatex>\(1\times 1\)</span>卷积层来将输入变换成需要的形状后再做相加运算。</p> <h3 id=763-resnet>7.6.3. ResNet模型<a class=headerlink href=#763-resnet title="Permanent link">&para;</a></h3> <p><img alt=ResNet18 src=../../../../../09.AI/NOTE-D2L/CH7-MODERN-CNN/resnet18.svg></p> <h3 id=764>7.6.4. 训练模型<a class=headerlink href=#764 title="Permanent link">&para;</a></h3> <h3 id=765>7.6.5. 小结<a class=headerlink href=#765 title="Permanent link">&para;</a></h3> <ul> <li>学习嵌套函数（nested function）是训练神经网络的理想情况。在深层神经网络中，学习另一层作为恒等映射（identity function）较容易（尽管这是一个极端情况）。</li> <li>残差映射可以更容易地学习同一函数，例如将权重层中的参数近似为零。</li> <li>利用残差块（residual blocks）可以训练出一个有效的深层神经网络：输入可以通过层间的残余连接更快地向前传播。</li> <li>残差网络（ResNet）对随后的深层神经网络设计产生了深远影响。</li> </ul> <h2 id=77-densenet>7.7. 稠密连接网络（DenseNet）<a class=headerlink href=#77-densenet title="Permanent link">&para;</a></h2> <p>ResNet极大地改变了如何参数化深层网络中函数的观点。 <em>稠密连接网络</em>（DenseNet）在某种程度上是ResNet的逻辑扩展。让我们先从数学上了解一下。</p> <h3 id=771-resnetdensenet>7.7.1. 从ResNet到DenseNet<a class=headerlink href=#771-resnetdensenet title="Permanent link">&para;</a></h3> <p>回想一下任意函数的泰勒展开式（Taylor expansion），它把这个函数分解成越来越高阶的项。在<span class=arithmatex>\(x\)</span>接近0时，</p> <div class=arithmatex>\[f(x) = f(0) + f'(0) x + \frac{f''(0)}{2!} x^2 + \frac{f'''(0)}{3!} x^3 + \ldots.\]</div> <p>同样，ResNet将函数展开为</p> <div class=arithmatex>\[f(\mathbf{x}) = \mathbf{x} + g(\mathbf{x}).\]</div> <p>也就是说，ResNet将<span class=arithmatex>\(f\)</span>分解为两部分：<strong>一个简单的线性项**和**一个复杂的非线性项</strong>。 那么再向前拓展一步，如果我们想将<span class=arithmatex>\(f\)</span>拓展成超过两部分的信息呢？ 一种方案便是DenseNet。</p> <p><img alt="ResNet（左）与 DenseNet（右）在跨层连接上的主要区别：使用相加和使用连结。" src=../../../../../09.AI/NOTE-D2L/CH7-MODERN-CNN/densenet-block.svg></p> <p><strong>如上图所示，ResNet和DenseNet的关键区别在于，DenseNet输出是*连接*（用图中的<span class=arithmatex>\([,]\)</span>表示）而不是如ResNet的简单相加。</strong> 因此，在应用越来越复杂的函数序列后，我们执行从<span class=arithmatex>\(\mathbf{x}\)</span>到其展开式的映射：</p> <div class=arithmatex>\[\mathbf{x} \to \left[ \mathbf{x}, f_1(\mathbf{x}), f_2([\mathbf{x}, f_1(\mathbf{x})]), f_3([\mathbf{x}, f_1(\mathbf{x}), f_2([\mathbf{x}, f_1(\mathbf{x})])]), \ldots\right].\]</div> <p>最后，将这些展开式结合到多层感知机中，再次减少特征的数量。 实现起来非常简单：我们不需要添加术语，而是将它们连接起来。 DenseNet这个名字由变量之间的“稠密连接”而得来，最后一层与之前的所有层紧密相连。 稠密连接如下图所示。</p> <p><img alt=稠密连接。 src=../../../../../09.AI/NOTE-D2L/CH7-MODERN-CNN/densenet.svg></p> <p>稠密网络主要由2部分构成：<strong><em>稠密块</em></strong>（dense block）和***过渡层***（transition layer）。 <strong>前者定义如何连接输入和输出，而后者则控制通道数量，使其不会太复杂。</strong></p> <h3 id=772>7.7.2. 稠密块体<a class=headerlink href=#772 title="Permanent link">&para;</a></h3> <p>DenseNet使用了ResNet改良版的“批量规范化、激活和卷积”架构。</p> <p>一个*稠密块*由多个卷积块组成，每个卷积块使用相同数量的输出通道。 然而，在前向传播中，我们将每个卷积块的输入和输出在通道维上连结。</p> <p>卷积块的通道数控制了输出通道数相对于输入通道数的增长，因此也被称为*增长率*（growth rate）。</p> <h3 id=773>7.7.3. 过渡层<a class=headerlink href=#773 title="Permanent link">&para;</a></h3> <p>由于每个稠密块都会带来通道数的增加，使用过多则会过于复杂化模型。 而过渡层可以用来控制模型复杂度。 它通过<span class=arithmatex>\(1\times 1\)</span>卷积层来减小通道数，并使用步幅为2的平均汇聚层减半高和宽，从而进一步降低模型复杂度。</p> <h3 id=774-densenet>7.7.4. DenseNet模型<a class=headerlink href=#774-densenet title="Permanent link">&para;</a></h3> <p>我们来构造DenseNet模型。DenseNet首先使用同ResNet一样的单卷积层和最大汇聚层。</p> <p>接下来，类似于ResNet使用的4个残差块，DenseNet使用的是4个稠密块。 与ResNet类似，我们可以设置每个稠密块使用多少个卷积层。 这里我们设成4，从而与ResNet-18保持一致。 稠密块里的卷积层通道数（即增长率）设为32，所以每个稠密块将增加128个通道。</p> <p>在每个模块之间，ResNet通过步幅为2的残差块减小高和宽，DenseNet则使用过渡层来减半高和宽，并减半通道数。</p> <h3 id=775>7.7.5. 训练模型<a class=headerlink href=#775 title="Permanent link">&para;</a></h3> <h3 id=776>7.7.6. 小结<a class=headerlink href=#776 title="Permanent link">&para;</a></h3> <ul> <li>在跨层连接上，不同于ResNet中将输入与输出相加，稠密连接网络（DenseNet）在通道维上连结输入与输出。</li> <li>DenseNet的主要构建模块是稠密块和过渡层。</li> <li>在构建DenseNet时，我们需要通过添加过渡层来控制网络的维数，从而再次减少通道的数量。</li> </ul> <form class=md-feedback name=feedback hidden> <fieldset> <legend class=md-feedback__title> Was this page helpful? </legend> <div class=md-feedback__inner> <div class=md-feedback__list> <button class="md-feedback__icon md-icon" type=submit title="This page was helpful" data-md-value=1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M5 9v12H1V9h4m4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21H9m0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03V19Z"/></svg> </button> <button class="md-feedback__icon md-icon" type=submit title="This page could be improved" data-md-value=0> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 15V3h4v12h-4M15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3h9m0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97V5Z"/></svg> </button> </div> <div class=md-feedback__note> <div data-md-value=1 hidden> Thanks for your feedback! </div> <div data-md-value=0 hidden> Thanks for your feedback! Help us improve this page by using our <a href=... target=_blank rel=noopener>feedback form</a>. </div> </div> </div> </fieldset> </form> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> 回到页面顶部 </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=页脚> <a href=../../CH6-CNN/ch6-cnn/ class="md-footer__link md-footer__link--prev" aria-label="上一页: 卷积神经网络"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 320 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> 上一页 </span> <div class=md-ellipsis> 卷积神经网络 </div> </div> </a> <a href=../../../RL/rl/ class="md-footer__link md-footer__link--next" aria-label="下一页: 强化学习"> <div class=md-footer__title> <span class=md-footer__direction> 下一页 </span> <div class=md-ellipsis> 强化学习 </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 320 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2021 ~ now | int32top </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://ppea.github.io target=_blank rel=noopener title=ppea.github.io class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M575.8 255.5c0 18-15 32.1-32 32.1h-32l.7 160.2c0 2.7-.2 5.4-.5 8.1V472c0 22.1-17.9 40-40 40h-16c-1.1 0-2.2 0-3.3-.1-1.4.1-2.8.1-4.2.1H392c-22.1 0-40-17.9-40-40v-88c0-17.7-14.3-32-32-32h-64c-17.7 0-32 14.3-32 32v88c0 22.1-17.9 40-40 40h-55.9c-1.5 0-3-.1-4.5-.2-1.2.1-2.4.2-3.6.2h-16c-22.1 0-40-17.9-40-40V360c0-.9 0-1.9.1-2.8v-69.6H32c-18 0-32-14-32-32.1 0-9 3-17 10-24L266.4 8c7-7 15-8 22-8s15 2 21 7l255.4 224.5c8 7 12 15 11 24z"/></svg> </a> <a href=https://github.com/ppea target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../../../../..", "features": ["announce.dismiss", "content.code.annotate", "content.tabs.link", "header.autohide", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.path", "navigation.prune", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "tags": {"Default": "default-tag", "Hardware": "hardware-tag", "Software": "software-tag"}, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=../../../../../assets/javascripts/bundle.081f42fc.min.js></script> <script src=../../../../../assets/javascripts/custom.2340dcd7.min.js></script> </body> </html>